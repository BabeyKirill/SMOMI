  Данная программа учится распознавать болезнь по снимкам грудной клетки. В отличии от lab2 здесь нужно было применить сеть VGG16 написанную самим и ещё отдельно VGG16 предобученную на imagenet. Файл MyVGG16.py - рукописная. Файл FreezedVGG16.py - файл для обучения классификатора при отключенном обучении модели VGG16. Файл UnfreezedVGG16.py - файл в котором обучение модели включено, он работает на основе файла полученного в результате работы FreezedVGG16.py.
  Результат работы файла MyVGG16.py получился плохим. По заданию нужно было определить оптимальный темп обучения lr, но я перепробовал много вариантов и ни в обном из них сеть не обучается. На картинке примеры вариантов с lr = 10^-9 до lr = 10^-6 и batch size = 8. Количество эпох 100, правда один из графиков дошёл до чуть больше 80 из-за того что программа прервалась, но результат и так понятен. На валидационных графиках видно, что сеть не обучается, на графиках обучения сеть тоже показывает себя плохо.

![Image alt](https://github.com/BabeyKirill/SMOMI/blob/lab3/MyVGG-6:-9.png)

Файл FreezedVGG16.py на значениях lr = 10^-6 и batch size = 16 выдал неплохой результат на 70-ти эпохах:

![Image alt](https://github.com/BabeyKirill/SMOMI/blob/lab3/Freezed70-6.png)

Но тут есть проблема переобучения и поэтому я уменьшил количество эпох до 40:

![Image alt](https://github.com/BabeyKirill/SMOMI/blob/lab3/Freezed40-6.png)

Далее с полученным предобученным классификатором работал UnfreezedVGG16.py, который при lr = 10^-11 показывал очень медленные 
изменения точности и потерь. Вот график для 120 эпох:

![Image alt](https://github.com/BabeyKirill/SMOMI/blob/lab3/Unfreezed120-11.png)

Чтобы это исрпавить, я увеличил lr до 10^-10, для 120 эпох результат получился неплохим.

![Image alt](https://github.com/BabeyKirill/SMOMI/blob/lab3/Unfreezed160-10.png)

Заключение: мне не удалось поределить оптимальный lr для рукописной VGG16, но для предобученной на imagenet оптимальный lr = 10^-6 для замороженной и 10^-10 для размороженной соответственно.

